# IIPS-Docker
Docker for IVH-ICH-PHE Segmentation

[![Build Status](https://github.com/llgneuroresearch/IIPS-Docker/actions/workflows/docker.yml/badge.svg)](https://hub.docker.com/r/avnirlab/iips/tags)
![GitHub Release](https://img.shields.io/github/v/release/llgneuroresearch/IIPS-Docker)
[![Documentation](https://img.shields.io/badge/Documentation-blue)](https://avnir-models-documentation.readthedocs.io/models/iips.html)

Docker container for IVH-ICH-PHE Segmentation based on nnU-Net, a self-configuring method for medical image segmentation.

The Dockerfile sets up an environment for running NNUNETV2 with PyTorch and CUDA support. It includes the necessary dependencies and configurations for NNUNETV2.

## Instructions

> [!NOTE]  
> Before using the following command lines. Docker and nvidia-container-toolkit must be installed. (`sudo apt install -y docker.io nvidia-container-toolkit` or `sudo apt install -y docker.io nvidia-docker2`)


### Building the Docker Image Manually

To build the Docker image, run the following command in the directory containing the Dockerfile:

```
docker build -t iips:latest
```

### Pulling the Docker Image from DockerHub

To pull the Docker image, run the following command:

```
docker pull avnirlab/iips:<tag>
```

1. Every time main branch is updated, the CICD build the Dockerfile and push the image to Dockerhub with latest tag, i.e. `avnirlab/iips:latest`

2. Every time a new tag is created, the CICD build the Dockerfile and push the image to Dockerhub with tag name e.g.: `avnirlab/iips:1.0.0`.

### Run inference

After building or pulling the Docker image, you can run inference on your nifti images.

> [!IMPORTANT]  
> If you want to run the inference using CUDA, please use NVIDIA driver 560 or higher and CUDA 12.6 or higher.

- Input

The input consists into a directory containing all your CT scans in Nifti format. Nifti files does not required a specific filename.

```
/project_root
├── input_data/               <-- Your source directory
│   ├── scan_001.nii.gz       (Filenames can be anything)
│   ├── patient_abc.nii       (Uncompressed Nifti works too)
│   ├── trauma_case_v2.nii.gz
│   └── 001_stroke_case.nii
```

- Output

Create an output folder where the brain masks will be saved.

- Command line

To run the inference, run the following command:

```
docker run -ti -v PATH_TO_INPUT:/input -v PATH_TO_OUTPUT:/output -u 0:$(id -g) --gpus all --rm --shm-size 2g avnirlab/iips:latest -device cuda
```

PATH_TO_INPUT and PATH_TO_OUTPUT must be absolute paths. If you want to run the inference on CPU, change `cuda` to `cpu` and remove `--gpus all` in the previous command line.
